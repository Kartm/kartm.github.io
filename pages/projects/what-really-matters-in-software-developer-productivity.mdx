import ProjectLayout from "../../layouts/project-layout";

export const meta = {
    title: 'What really matters in software developer productivity: a 105-dev survey',
}

{/*
todo this layout https://bun.com/blog/behind-the-scenes-of-bun-install?utm_source=unknownews
*/}

<ProjectLayout meta={meta}>

# What really matters in software developer productivity: a 105-dev survey

## TL;DR
Survey reveals what actually affects delivery: clear requirements, appropriate resources, insightful code reviews, basic CI/CD, allocating tech-debt time. Choice of communication tools and "raw coding hours" matter less.

## Quick wins

By addressing common problems and making small improvements, teams can see immediate benefits, such as faster task completion and higher morale. Practical recommendations that can be implemented right away:

| Action steps                                                                                                                                      | Expected benefit                                                   |
|---------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------|
| **Automate the small stuff** <br/> - Configure basic CI/CD pipelines for builds, tests, and deployments <br/> - Integrate code linters/formatters                                         | Reduces manual errors, saves developer time, and removes repetitive style discussions |
| **Improve task clarity** <br/> - Remember to clear up uncertainties during daily stand-ups <br/> - Thoroughly refine tickets before work begins                                   | Minimizes confusion, avoids rework caused by unclear requirements    |
| **Tweak meeting cadence** <br/> - Consolidate topics into one session <br/> - Invite only essential participants                                                               | Reduces context switching, frees up time for deep work             |
| **Refine communication** <br/> - Introduce "quiet hours" <br/> - Encourage asynchronous updates when possible                                                                | Preserves concentration, decreases frequent interruptions          |
| **Micro-refactoring** <br/> - Schedule small refactoring tasks each sprint <br/> - Fix minor "code smells" early                                                           | Prevents technical debt from compounding over time                 |
| **Immediate recognition** <br/> - Celebrate small wins with your team <br/> - Acknowledge code review or task completions                                                      | Boosts morale, promotes positive team culture                      |


## Long-term strategies

More comprehensive changes that require more time and effort to implement, but may lead to prolonged improvements in developer efficiency:

| Action steps                                                                                                                                   | Expected benefit                                                                 |
|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| **Implement effective planning** <br/> - Adopt robust requirement practices (e.g., backlog grooming, user story mapping)                                                             | Reduces misunderstandings and rework; improves transparency in project scope    |
| **Promote a smooth code review culture** <br/> - Define code review SLAs (e.g., max 24-hour turnaround)<br/>- Emphasize mentorship by explaining the "why" behind suggestions                   | Keeps tasks flowing, improves knowledge sharing, and increases developer confidence |
| **Systematically address tech debt** <br/> - Allocate a consistent share of each sprint (e.g., 10–20%) for refactoring<br/>- Maintain a visible "technical debt board" to prioritize items by risk and impact | Prevents legacy issues from piling up; ensures sustainable code quality over time |
| **Promote adaptable work environments** <br/> - Offer flexible policies (remote, on-site, or hybrid) based on team and project needs<br/>- Use team-building events to maintain connection | Balances productivity with well-being; mitigates isolation and helps retain talent |
| **Support well-being & recognition** <br/> - Schedule regular 1:1s for feedback, goal-setting, and personal challenges<br/>- Provide "no-blame" retrospectives and genuine appreciation for efforts | Builds psychological safety, reduces burnout, and improves teamwork         |


![Developer productivity hero](/media/media/developer-productivity-hero.jpg "Developer productivity hero")

# Introduction

I found advice on dev productivity often anecdotal, so I performed a survey to see first-hand what has a real impact on developer productivity.

I used [SPACE framework](https://queue.acm.org/detail.cfm?id=3454124) to view productivity with a multidimensional take:

* **Satisfaction**: Understanding developers' well-being is crucial because stress, lack of recognition, or poor work-life balance can negatively affect productivity.

* **Performance**: Evaluating how well developers meet goals and deadlines provides insight into whether existing tools and processes are effectively supporting them.

* **Activity**: Understanding how daily tasks are managed helps highlight bottlenecks and time-wasting activities that can reduce productivity.

* **Communication**: Effective teamwork and communication are essential in software development. Problems in collaboration can lead to delays, misaligned goals, or rework.

* **Efficiency**: How smoothly developers can complete tasks without disruptions. Interruptions, long wait times for code reviews, or the burden of technical debt can reduce flow, making it harder for developers to stay productive.

In late 2024 I have conducted a **10-week-long survey on 105 developers** recruited from social media platforms (e.g., LinkedIn, Reddit), professional forums (e.g., HackerNews), and various software development communities. This allowed me to capture a wide range of backgrounds, including differences in experience level, technology stacks, team sizes, and organizational types.

![Respondent age group distribution](/media/media/age-distribution.svg "Respondent age group distribution")

More than 77% participants were under the age of 35, indicating that the survey mostly reached a **relatively young** segment of the industry. Age can influence familiarity with technologies and preferences for communication styles.

![Respondent gender distribution](/media/media/gender-distribution.svg "Respondent gender distribution")

Around 85% respondents were male.

Female respondents accounted for around 12% of the responses. According to [SlashData's 2023 Developer Nation survey](https://www.developernation.net/developer-reports/dn25/) performed on 8380 developers, the share of female developers oscillates around 23% globally, indicating that this study might base on a sample that's underrepresenting the female part of the industry, therefore performing analysis between genders would make little sense and possibly introduce bias.

> [!IMPORTANT]
> The survey sample is skewed towards young (~77% under 35), male (~85%), and more experienced developers; juniors and women are under-represented.

![Respondent job role distribution](/media/media/job-role-distribution.svg "Respondent job role distribution")

Around 86% of respondents reported being directly involved in development and engineering. Another 8% were also involved, but on a higher level (conceptual work, architecture and technical leadership). Remaining 6% were site administrators, support engineers or other roles.

![Respondent primary expertise area vs work experience level distribution](/media/media/expertise-area-distribution.svg "Respondent primary expertise area vs work experience level distribution")

I have reached developers with wide ranges of experience levels, useful factor to compare later. Expertise areas were a multi-choice field. Most frequent choices are back-end & front-end development and DevOps, and were predominantly made by developers having more than 2 years of experience in the industry. Developers with **less experience seem to be significantly underrepresented**, therefore it wouldn't make sense to analyze junior developers in the survey.

![Respondent-reported project scale distribution](/media/media/project-scale-distribution.svg "Respondent-reported project scale distribution")

Only 6% of respondents report to work in simple projects (involving predictable tasks, few dependencies, and straightforward requirements).

Project scale impacts the complexity and types of challenges teams face, with larger projects requiring more coordination and resources.

![Respondent team and workplace size distribution](/media/media/workplace-team-distribution.svg "Respondent team and workplace size distribution")

34% of participants are engaged in small teams of 3 to 5 members, while 44% operate within medium-sized teams consisting of 6 to 15 members. Making a comparison between these two team sizes is an opportunity to understand how team composition influences other measured factors.

# Work environment vs job satisfaction

Work environment is not only the physical space where developers work (remote, on-site, hybrid). It also includes the mental environment: team culture, motivation factors, stress levels.

First, to compare work environments (remote, hybrid, on-site), appropriate scales were introduced so that **higher values == "better"**.

![Radar plot comparing satisfaction of remote, hybrid, and on-site respondents](/media/media/work-satisfaction-distribution.svg "Radar plot comparing satisfaction of remote, hybrid, and on-site respondents")

Hybrid developers often report more frequent achievement recognition, whereas on-site developers seem to suffer more frequently from impostor syndrome yet report lower stress overall, suggesting social interaction might reduce stress but also provoke negative self-assessment.

Summarizing by calculating the area of respective polygons indicates that hybrid developers generally report better well-being than on-site developers:

| **Environment** | **Area** |
|-----------------|----------|
| Hybrid          | 31.6     |
| Remote          | 29.0     |
| On-site         | 27.2     |

Some open answers reveal that an in-office environment sets **better boundaries between personal and professional life**, and remote workers often find it hard to "switch off", as one respondent notes:

> If you're not careful, working at home means you never truly leave 'the office.'

Other respondents cite the need for better recognition and manager appreciation:

> \[...\] how do we give the work done by developers the appropriate value and reward? I think that would improve productivity greatly.

> Who the developer is matters more than anything. Want more productive people? Show them they matter to you. Treat people well and get out of their way.

> [!IMPORTANT]
> Respondent feedback seems to support the statement that the hybrid environment connects the best of both worlds and developers are generally more satisfied working in hybrid mode.

There are even more differences in how developers experience remote-only work.

Remote teams enjoy flexibility and asynchronous work but risk more alignment calls, digital interruptions, and self-discipline hurdles. Onsite/hybrid teams benefit from rapid in-person collaboration yet face noise and social intrusions.

# Planning, deployment and developer productivity

Let's see how developers perceive their own momentum and ability to deliver on time.

![Distribution of frequencies of developers meeting their deadlines](/media/media/meeting-deadlines-distribution.svg "Distribution of frequencies of developers meeting their deadlines")

On average, participants manage to deliver mostly on time.

![Distribution of frequencies of developers meeting their deadlines by developer experience level](/media/media/meeting-deadlines-across-developer-experience.svg "Distribution of frequencies of developers meeting their deadlines by developer experience level")

Surprisingly, the average self-reported deadline meeting frequency slightly decreases with experience. It might be caused by the fact that junior developers have well-defined tasks, whereas senior developers usually have very vast tasks across many moving parts.

With increased expertise, many experienced developers set a higher standard for defining a task as "done", introducing a possible self-critical bias when answering the survey.

Senior team members frequently wear multiple hats: mentoring, product coordination, production support. These extra responsibilities might cause additional overhead, delaying their own coding tasks and leading to missed deadlines.

Overall, this does not necessarily imply that senior developers are less productive. Rather it suggests they may face more complex challenges, as one senior respondent noted in a separate comment:

> A few days' delay on a major architectural change may feel more serious than a small missed deadline on an isolated ticket.

![Average deadline-reaching frequency by obstacle type](/media/media/meeting-deadlines-by-obstacle-type.svg "Average deadline-reaching frequency by obstacle type")

Developers lacking resources and developers complaining about unclear requirements were the group least effective in reaching deadlines. Let's explore this by comparing team sizes.

![Distribution of deadline-reaching obstacles by team size](/media/media/deadline-obstacles-by-team-size.svg "Distribution of deadline-reaching obstacles by team size")

Scope creep appears universal across all team sizes, highlighting that no matter how large the team is, changing requirements and additional features remain a main threat to on-time delivery.

* **Smallest teams**: often cite a lack of resources (e.g., insufficient team members or missing tools) as a primary reason for missing deadlines. Most likely individuals have specialized skillsets, and any absence of expertise or tooling can cause major bottlenecks.

* **Mid-sized teams** (3–15 members) show a more balanced distribution of obstacles, with scope creep and unclear requirements being consistently present. They typically have enough staff to handle various tasks but may face communication overhead or shifting priorities.

* **Very large teams** (31+ members) also report lack of resources, which might seem counterintuitive at first. A possible explanation is that in big organizations, specialized resources are sometimes tied to specific departments, or bureaucratic processes slow down obtaining the right tools or staff.

![Distribution of deadline-reaching obstacles by workplace size ](/media/media/deadline-obstacles-by-workplace-size.svg "Distribution of deadline-reaching obstacles by workplace size ")

* **Very small workplaces** (fewer than 10 employees) frequently struggle with unclear requirements and rapid pivoting, which can make hitting deadlines more challenging. Their focus on speed and experimentation might overshadow formal planning.

* **Medium-sized workplaces** tend to have more stable processes, so they rather report scope creep or internal dependencies instead of constant requirement changes.

* **Larger enterprises** show a spread of different challenges: some mention hidden complexity in legacy systems. Even though they have more established procedures, the slow decision-making and multiple layers of management can slow progress.

> [!IMPORTANT]
> Across team sizes and company sizes, scope creep and unclear requirements are the usual blockers of on-time delivery. Adding people doesn't fix unclear scope.

![Distribution of deadline-reaching frequencies by team size ](/media/media/meeting-deadlines-by-team-size.svg "Distribution of deadline-reaching frequencies by team size ")

The data indicates only minor differences in how often teams of various sizes manage to meet deadlines.

No single team size clearly guarantees timely delivery. Instead, coordination, clarity of requirements, and resource availability seem to matter more than raw headcount.

![Distribution of deadline-reaching frequencies by workplace size ](/media/media/meeting-deadlines-by-workplace-size.svg "Distribution of deadline-reaching frequencies by workplace size ")

Smallest workplaces are the most prone to missing deadlines, likely because they rely on quick pivots, minimal processes, and sometimes underdeveloped planning strategies. One survey respondent captured this perfectly:

> I would start by improving the management, making it mandatory for them to be organized and to give requirements in a planned way. \[...\]

Some big organizations still cope with heavy bureaucracy that can slow delivery, despite having more resources. As one respondent from a large workplace notes:

> "Less bureaucracy in a large company."

### The impact of CI/CD

![Distribution of deployment times among respondents](/media/media/deployment-time-distribution.svg "Distribution of deployment times among respondents")

Most respondents can deploy changes in under 30 minutes, but around 30% mention they need an hour or more. Developers with longer deployment times often mention manual checks and gating processes, leading to decreased velocity.

Comments from respondents suggest that manual steps create extra stress and slow the momentum of each release. However, it's not always possible to fully automate everything. Some teams deal with hardware dependencies or environment constraints that make continuous delivery hard. But for pure software teams, many see automation as a major boost to daily productivity.

![Distribution of deployment times among respondents who automate the process vs those who don't](/media/media/deployment-time-distribution-automated-vs-non-automated.svg "Distribution of deployment times among respondents who automate the process vs those who don't")

Teams with automated deployment show a slightly faster average deployment time. While automation alone might not fix every bottleneck (e.g. compliance processes), generally those with automation in place achieve quicker, more predictable releases.

> [!IMPORTANT]
> Basic CI/CD (builds, tests, deploy) is linked with shorter and more predictable releases. Automate the deployment path.

# Time spent on coding vs meeting deadlines

Lack of resources, organizational bottlenecks, and unclear requirements appear as main obstacles to meeting deadlines. Hidden complexity (technical debt, legacy code) and CI/test-related problems rank lower in this analysis. Perhaps developers manage to correctly estimate them.

![Distribution of average deadline-reaching frequencies by deadline obstacle type](/media/media/meeting-deadlines-by-obstacle-type.svg "Distribution of average deadline-reaching frequencies by deadline obstacle type")

> [!IMPORTANT]
> Results suggest that unclear requirements can undermine deadline timelines just as much as lack of resources. If a team is already operating with limited manpower or budget, unclear or shifting project requirements can make things worse.

Legacy code and CI-related challenges are rarely deadline blockers. While legacy systems can be time-consuming, they are relatively predictable once developers understand the codebase. On the other side, unclear requirements can constantly shift, causing repeated rework. Their unpredictability creates far more serious risks to the schedule.

![Distribution of average deadline-reaching frequencies by developer experience level and work environment type](/media/media/time-spent-on-coding-vs-deadlines.svg "Distribution of average deadline-reaching frequencies by developer experience level and work environment type")

One interesting observation is that deadlines seem to be reached less often with experience, regardless of work environment type. Possibly because more complex tasks become more unpredictable.

# Do communication tools matter?

Developers rarely have the freedom to choose their preferred communication tool, it is rather a requirement of the employer. Let's examine how satisfied they are with them.

![Distribution of communication tools among respondents](/media/media/primary-collaboration-tool-usage.svg "Distribution of communication tools among respondents")

* **Microsoft Teams** seems to be the leader in big corporations, probably because these companies already use the Microsoft Office suite, so it's a natural choice to opt in with Teams for additional integrations as they are already deep into the ecosystem.

* **Slack** seems to be less popular with the biggest companies, and is rather a choice for mid-sized companies.

* **Google Chat** has a considerable user base in large companies, most likely due to being in the Google Workspace suite, but it remains the least popular of the "big three".

* Other choices included Discord, Mattermost, internal tools and plain emails. They will not be extensively covered further.

![Average communication tools ratings among respondents ](/media/media/communication-tools-satisfaction.svg "Average communication tools ratings among respondents ")

Satisfaction scores indicate that Slack is the best rated tool, followed by Google Chat and Microsoft Teams, which also hold a wider distribution of satisfaction scores.

To explore why, open-ended responses were analyzed and paraphrased to preserve anonymity, revealing common user sentiments about each tool.

## Slack

Many respondents praise threading & organization: many highlight Slack's threaded conversations, flexible channel architecture, "lightweight feel" for daily tasks and advanced search. Developer workflows are a big plus thanks to integrations with GitHub/GitLab, slash commands.

Some respondents however noted its limited impact on efficiency: one respondent noted Slack "has never had an effect on my efficiency", calling it simply "functional". Some see Slack just as an alternative to other platforms.

## Microsoft Teams

People appreciate how Teams syncs with Outlook, corporate auth (AD/SSO), and the Office ecosystem and how calendar, calls, and chat are consolidated in one place to avoid distractions.

It has received negative feedback for being resource-heavy & bloated: several respondents called it "slow", "clunky" or prone to random sign-outs, buggy screen-sharing issues. Teams forced to migrate from Slack reported negative morale and "cumbersome integration capabilities" compared to Slack.

## Google Chat

Praised for being lightweight & quick to setup. Minimal clutter, easy adoption, and low friction if you already use Gmail or Google Docs. Perfect for basic messaging: fine for smaller teams or simple chats. Meeting links or simple file-sharing are quick.

It has its limitations and is missing advanced features: lacks powerful slash commands or robust thread management. In some cases accessibility is subpar: browser/extension incompatibilities, especially for text-based browsing.

![Impact of work environment on efficiency by communication tool](/media/media/communication-tools-impact-on-efficiency.svg "Impact of work environment on efficiency by communication tool")

Looking at how respondents evaluate their overall work environment (e.g., workplace satisfaction, perceived productivity, and clarity of tasks), Slack and Google Chat users display fairly similar, positive ratings of their environment. Microsoft Teams users, however, appear to rate their environment slightly lower on average.

![Flow interruptions frequency by communication tool](/media/media/communication-tools-interruptions-frequency.svg "Flow interruptions frequency by communication tool")

Choice of communication tool alone may not drastically affect how frequently developers are interrupted. Instead, interruptions may be originate from the organizational culture and scheduling practices than the platform itself.

![Flow interruptions types by communication tool](/media/media/interruption-types-by-communication-tool.svg "Flow interruptions types by communication tool")

Given Microsoft Teams' tight integration with Outlook, and Google Chat's integration with Gmail, it's unsurprising that these platforms might push more message or calendar alerts into developers' daily flow.

> [!IMPORTANT]
> Tool choice slightly affects satisfaction (Slack > Chat > Teams in this sample), but interruption rate is affected more by work culture and scheduling than by the chat tool itself.

# Can code reviews affect well-being of developers?

Peer code reviews are a common practice in software development teams. It's a means of finding errors and logical mistakes.

However, extended review cycles can delay merges, especially in busy teams. Prolonged branches or unresolved pull requests risk creating "merge hell", which can lead to massive delays, potentially increasing technical debt.

Let's discover the impact of code review processes on developers.

![Distribution of code review wait times](/media/media/code-review-wait-times.svg "Distribution of code review wait times")

Respondents can be categorized depending on how long they wait for code reviews:

- **Delayed**: those who reported typically waiting more than 1 day.

- **Fast**: those who typically wait 1 day or less.

1 day is a practical cut-off to distinguish quick-feedback reviews from those that might disrupt flow and create bottlenecks.

Additionally, developers were grouped based on the perceived impact of receiving code reviews.

- **Helpful**: ratings of 4 or 5 (positive).

- **Unhelpful**: ratings of 1, 2, or 3.

Each respondent was assigned to one of these four groups based on their survey answers about wait time and perceived impact. This categorization allows us to compare whether these groups systematically differ.

![Mean well-being categories by code review group](/media/media/code-review-well-being.svg "Mean well-being categories by code review group")

- **Highest stress**: *Unhelpful & Delayed*. When feedback is late and of poor quality, developers report feeling blocked and undervalued, aligning with the hypothesis that such conditions intensify stress.

- **Lowest stress**: *Helpful & Delayed*. Surprisingly, even though reviews come late, if the feedback is eventually constructive and collaborative, participants often report being less stressed. Perhaps these developers work in an environment with flexible deadlines or more empathetic management—so even a delayed review is not perceived as a severe bottleneck.

- **Lowest recognition**: Tends to cluster in the *Unhelpful & Fast* group. This suggests that such feedback is rushed, consists of purely checking boxes and rarely involves praise.

- **Higher recognition**: *Helpful* groups (whether prompt or delayed) generally reported feeling more appreciated. Good feedback promotes a sense of support and achievement.

- **Worst impostor ratings**: *Unhelpful & Fast*. Despite getting quick feedback, if the reviews are not constructive or are purely "nitpicky", developers might feel their work is constantly under scrutiny without providing actual support. This aligns with the idea that the quality of feedback matters deeply for confidence.

- **Mixed impostor syndrome results**: *Unhelpful & Delayed* also scores high on impostor syndrome but not the worst. Individual circumstances and other confounding variables (e.g., how the team interacts outside formal reviews) could account for the difference.

> [!IMPORTANT]
> Set review SLAs (less than 24 hours) and expectations (ask for reasoning, not nitpicks). Quality is more important than speed, but no one should wait days for feedback.

## Shared ownership

In addition to timeliness and quality, some respondents highlighted the value of sharing ownership, and even distributing "blame" through collaborative code review practices:

> "Blame on bugs plays a big role in software development. If the blame is spread across the team by Code Reviews and team tasks, I believe the team is healthier and happier".

> "\[...\] You can achieve a great result by having the right team leadership, great team culture or sharing team responsibilities (the more responsibility you have the more you care about product/project)".


> [!IMPORTANT]
> Code reviews can promote collective accountability, reducing stress and promoting a positive team culture, particularly when everyone feels invested in the outcome. However, quality, tone, and collaborative spirit of feedback are also critical to reduce stress levels, impostor feelings, and to increase positive recognition.

![Code review wait time vs. code review quality](/media/media/code-review-wait-time-vs-quality.svg "Code review wait time vs. code review quality")

This aligns with participants' answers to open-ended questions regarding their experiences with code reviews:

## Positive code-review experience

- **Timely and constructive feedback**: several respondents noted that quick turnaround and thoughtful feedback boosts confidence. They feel that even small acknowledgments of good coding practices or improvements helps them grow.

- **Collaborative approach**: supportive, discussion-based review culture makes developers feel recognized and reduces impostor syndrome by showing that their work has real value.

- **Learning opportunity**: respondents who praised code reviews often viewed them as mentorship moments, where suggestions go beyond simple fixes to real skill-building.

## Negative code-review experience

- **Prolonged wait times**: these delays increase stress and force context-switching, undermining developers' flow and leaving them uncertain about the quality of their prior work.

- **"Rubber-stamped" reviews**: such feedback leaves developers feeling underappreciated (lack of achievement acknowledgment) and provokes impostor syndrome, as they never receive substantial validation or guidance.

- **Minimal praise, unclear expectations**: respondents describe wanting to understand why something is correct or praiseworthy, not just a quick sign-off. In the absence of real insight, they are unsure about their competence.

![Perceived code review impact on quality per developer experience level](/media/media/code-review-wait-time-vs-quality-across-dev-experience.svg "Perceived code review impact on quality per developer experience level")

Developers rate the impact of code reviews on quality of their work differently, depending on experience level.

## Junior developers (0–2 years of experience)

For the **few individuals** in this group, their recorded "review quality" tends to improve with longer wait times, a counterintuitive finding. Due to the minimal number of junior respondents, we treat this as non-representative.

One junior-type respondent mentioned doing all code reviews solo, effectively receiving no peer input. Another, dealing with a **very long** wait, expressed frustration about a siloed environment where colleagues are unwilling to review.

Both examples confirm that "long" or "fast" reviews can become meaningless if genuine peer interaction is missing, complicating any numeric findings.

## Mid-level developers (3–6 years of experience)

Mid-level devs appreciate code reviews less when forced to wait longer. **Timeliness seems crucial** to maintaining flow and momentum in their daily tasks.

Several respondents in this group reported fast reviews but described the feedback as unhelpful: describing the feedback as "contradictory", "purely nitpicking", or effectively nonexistent. This underscores that short wait times alone do not yield positive results if the review's quality is poor.

## Senior developers (\>7 years of experience)

More experienced developers tolerate slight delays (perhaps seeing them as a sign of extensiveness) but report a **steep decline** in perceived quality after a waiting for more than three days.

Some respondents indicated that very long waits often result in no actual review, or solely a neutral/box-ticking process. Another respondent reported a mismatch in team expertise, where they receive minimal feedback from junior colleagues.

# Tech debt: the balance between effort and impact

Technical debt can be boiled down to the accumulated cost of **suboptimal or quickly implemented** code that can slow down future development. While technical debt is often introduced for temporary reasons (e.g. meeting short-term deadlines or rapidly prototyping), it slows development down if left unaddressed. Many respondents mentioned legacy code, missing documentation, and poorly structured modules as factors slowing daily work.

![Impact of tech debt time on deadline-reaching frequencies, deployments/month, rating of tech debt impact, developer stress level](/media/media/impact-of-time-spent-on-tech-debt.svg "Impact of tech debt time on deadline-reaching frequencies, deployments/month, rating of tech debt impact, developer stress level")

It seems apparent that teams spending the most time on tech debt rarely reach deadlines, and at the same time report the highest number of deployments per month.

Respondents spending more than 75% of their time paying tech debt are experiencing stress more often.

> [!IMPORTANT]
> High, unaddressed tech debt can lead not only to increased stress levels among developers, but also to delay project schedules.

## Open-ended feedback on tech debt

Respondents had the possibility to explain how tech debt impacts their productivity.

![Common words from feedback negatively rating the effect of tech debt on their productivity](/media/media/negative-tech-debt-impact-on-productivity.svg "Common words from feedback negatively rating the effect of tech debt on their productivity")

Developers that reported negative impact of tech debt on their productivity see technical debt as an ongoing struggle. They regularly reach blockers or fight friction whenever they try to implement new features.

* **Legacy code & poor documentation**: many mention inherited undocumented systems that slow all tasks. Old code bases appear hard to work on, so each change risks new bugs or confusion.

* **Insufficient time to address debt**: being the only developer or working under tight deadlines leads to rare refactoring at best. Because no formal process or time is allocated, they only fix issues when absolutely necessary.

* **Lack of management support**: some note that higher-level leaders do not care about code quality, prioritizing quick feature delivery instead. Over time, this approach worsens the code structure and forces developers to fight with messy parts.

* **Chaotic or entangled modules**: respondents describe multiple "workarounds" or severely "entangled" code paths, making any enhancement risky. Without stable foundations, even small tasks involve disproportionately high effort.

![Common words from feedback non-negatively rating the effect of tech debt on their productivity](/media/media/positive-tech-debt-impact-on-productivity.svg "Common words from feedback non-negatively rating the effect of tech debt on their productivity")

Developers perceiving tech debt as positive don't claim zero debt. Rather they report having practical control of it.

* **Balanced approach**: some believe they have "just enough" debt. They do not see it as severely blocking progress.

* **In the process of paying down**: certain respondents actively schedule refactoring or "technical debt tickets" each sprint. While debt is present, regular backlog management keeps it from getting out of control.

* **Selective or targeted fixes**: some fix easy items (e.g. small code smells) right away and document the bigger ones for future tasks.

* **Awareness of code hotspots**: respondents emphasize that if you know which parts of the code are most affected by tech debt (**"hotspots"**), it is easier to address them on demand. Although not perfect, this strategy stops the worst side effects from unmaintained areas.

> [!IMPORTANT]
> Regularly allocating time for debt appears beneficial. The best outcomes seem to appear when debt is managed in **consistent but balanced** manner, avoiding both full-blown rewrites and complete neglect.

## Credits

* Hero image by [Olivier Amyot](https://unsplash.com/photos/the-mug-shows-the-development-process-steps-WvuS4BQ94XQ)

</ProjectLayout>